{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# fmt: off\n",
    "from Utilities.Interpretability.ModelAugmentation import *\n",
    "from Utilities.Interpretability.InterpretabilityMethods import *\n",
    "from Utilities.Tasks.CIFAR10ClassificationTask import CIFAR10ClassificationTask as Task\n",
    "from Utilities.SequentialLearning.EWC_Methods.EWC_Methods import *\n",
    "from Utilities.SequentialLearning.EWC_Methods.ImportanceMeasureOrderings import validation_loss_by_importance_threshold\n",
    "from Utilities.Interpretability.ModelAugmentation import ComparisonMethod, AggregationLevel, AggregationMethod\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "# fmt: on\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"models/CIFAR10_medium_model/\"\n",
    "LOAD_MODEL = False\n",
    "TRAIN_MODEL = not LOAD_MODEL\n",
    "RUN_EAGERLY = False\n",
    "\n",
    "image_size = Task.IMAGE_SIZE\n",
    "task_labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "model_input_shape = image_size\n",
    "training_batches = 0\n",
    "validation_batches = 0\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING MODEL\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_0 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 1, 1, 256)         295168    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 928,810\n",
      "Trainable params: 928,426\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model: tf.keras.Model\n",
    "if LOAD_MODEL and os.path.exists(MODEL_SAVE_PATH):\n",
    "    # Try to load model directly, if one exists\n",
    "    print(\"LOADING MODEL\")\n",
    "    model = tf.keras.models.load_model(MODEL_SAVE_PATH, compile=False)  # type: ignore\n",
    "else:\n",
    "    # Otherwise, make an entire new model!\n",
    "    print(\"CREATING MODEL\")\n",
    "    model_inputs = model_layer = tf.keras.Input(shape=model_input_shape)\n",
    "    model_layer = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", name=\"conv2d_0\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", name=\"conv2d_1\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", name=\"conv2d_2\")(model_layer)\n",
    "    model_layer = tf.keras.layers.BatchNormalization()(model_layer)\n",
    "    model_layer = tf.keras.layers.MaxPool2D((2,2))(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", name=\"conv2d_3\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", name=\"conv2d_4\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", name=\"conv2d_5\")(model_layer)\n",
    "    model_layer = tf.keras.layers.BatchNormalization()(model_layer)\n",
    "    # model_layer = tf.keras.layers.MaxPool2D((2,2))(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", name=\"conv2d_6\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", name=\"conv2d_7\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", name=\"conv2d_8\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Flatten()(model_layer)\n",
    "    model_layer = tf.keras.layers.Dense(128, activation=\"relu\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Dropout(0.2)(model_layer)\n",
    "    model_layer = tf.keras.layers.Dense(128, activation=\"relu\")(model_layer)\n",
    "    model_layer = tf.keras.layers.Dropout(0.2)(model_layer)\n",
    "    model_layer = tf.keras.layers.Dense(len(task_labels))(model_layer)\n",
    "    model = tf.keras.Model(inputs=model_inputs, outputs=model_layer, name=\"base_model\")\n",
    "if len(task_labels) == 2:\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "else:\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_augmentation = None\n",
    "training_image_augmentation = tf.keras.Sequential([\n",
    "    # tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomZoom(\n",
    "            height_factor=(-0.05, -0.25),\n",
    "            width_factor=(-0.05, -0.25)),\n",
    "    tf.keras.layers.RandomRotation(0.05, \"constant\")\n",
    "])\n",
    "\n",
    "task = Task(\n",
    "        name=f\"Task 0\",\n",
    "        model=model,\n",
    "        model_base_loss=loss_fn,\n",
    "        task_labels=task_labels,\n",
    "        training_batches = 0,\n",
    "        validation_batches = 0,\n",
    "        batch_size=batch_size,\n",
    "        training_image_augmentation = training_image_augmentation,\n",
    "        run_eagerly=RUN_EAGERLY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewc_methods = [\n",
    "    EWC_Method.FISHER_MATRIX,\n",
    "    EWC_Method.SIGN_FLIPPING,\n",
    "    EWC_Method.MOMENTUM_BASED,\n",
    "    EWC_Method.WEIGHT_CHANGE,\n",
    "    # EWC_Method.WEIGHT_MAGNITUDE,\n",
    "    # EWC_Method.INVERSE_WEIGHT_MAGNITUDE,\n",
    "    EWC_Method.RANDOM,\n",
    "]\n",
    "\n",
    "aggregation_levels = [\n",
    "    AggregationLevel.NO_AGGREGATION,\n",
    "    # AggregationLevel.UNIT,\n",
    "    AggregationLevel.CONV_FILTER,\n",
    "]\n",
    "\n",
    "# ewc_methods = [EWC_Method.WEIGHT_CHANGE, EWC_Method.INVERSE_WEIGHT_MAGNITUDE, EWC_Method.RANDOM, EWC_Method.FISHER_MATRIX]\n",
    "ewc_term_creators = [EWC_Term_Creator(ewc_method, model, callback_kwargs={\"reset_on_train_begin\": False}) for ewc_method in ewc_methods]\n",
    "\n",
    "# Add all callbacks from all terms to the callback list\n",
    "callbacks = []\n",
    "for ewc_term_creator in ewc_term_creators:\n",
    "    for k,v in ewc_term_creator.callback_dict.items():\n",
    "        callbacks.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = [\"Epoch\", \"EWC Method\", \"Aggregation Level\", \"Threshold Value\", \"Loss\", \"Validation Loss\"]\n",
    "all_results_dataframe = pd.DataFrame(columns=column_names)\n",
    "num_samples = 25\n",
    "num_epochs = 25\n",
    "sample_period = 5\n",
    "sample_array = [(1/num_samples) * i for i in range(num_samples+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   6/1562 [..............................] - ETA: 1:42 - loss: 1.9431 - base_loss: 1.9431WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.0588s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.0588s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 111s 68ms/step - loss: 1.6292 - base_loss: 1.6292 - val_loss: 1.6748 - val_base_loss: 1.6748\n",
      "Epoch 2/5\n",
      "1562/1562 [==============================] - 111s 71ms/step - loss: 1.3214 - base_loss: 1.3214 - val_loss: 1.3934 - val_base_loss: 1.3934\n",
      "Epoch 3/5\n",
      "1562/1562 [==============================] - 113s 72ms/step - loss: 1.1149 - base_loss: 1.1149 - val_loss: 1.1355 - val_base_loss: 1.1355\n",
      "Epoch 4/5\n",
      "1562/1562 [==============================] - 109s 70ms/step - loss: 0.9910 - base_loss: 0.9910 - val_loss: 1.4068 - val_base_loss: 1.4068\n",
      "Epoch 5/5\n",
      "1562/1562 [==============================] - 109s 70ms/step - loss: 0.8964 - base_loss: 0.8964 - val_loss: 0.9800 - val_base_loss: 0.9800\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: NO_AGGREGATION\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: NO_AGGREGATION                                     \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: CONV_FILTER                                        \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: NO_AGGREGATION                                             \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: CONV_FILTER                                                \n",
      "threshold_value=1.0                                                                                 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   6/1562 [..............................] - ETA: 1:42 - loss: 0.7969 - base_loss: 0.7969WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0117s vs `on_train_batch_end` time: 0.0540s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0117s vs `on_train_batch_end` time: 0.0540s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 110s 67ms/step - loss: 0.8256 - base_loss: 0.8256 - val_loss: 0.8597 - val_base_loss: 0.8597\n",
      "Epoch 2/5\n",
      "1562/1562 [==============================] - 110s 71ms/step - loss: 0.7739 - base_loss: 0.7739 - val_loss: 0.9459 - val_base_loss: 0.9459\n",
      "Epoch 3/5\n",
      "1562/1562 [==============================] - 112s 71ms/step - loss: 0.7136 - base_loss: 0.7136 - val_loss: 1.2439 - val_base_loss: 1.2439\n",
      "Epoch 4/5\n",
      "1562/1562 [==============================] - 108s 69ms/step - loss: 0.6742 - base_loss: 0.6742 - val_loss: 0.8084 - val_base_loss: 0.8084\n",
      "Epoch 5/5\n",
      "1562/1562 [==============================] - 109s 70ms/step - loss: 0.6341 - base_loss: 0.6341 - val_loss: 0.9678 - val_base_loss: 0.9678\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: NO_AGGREGATION\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: NO_AGGREGATION                                     \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: CONV_FILTER                                        \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: NO_AGGREGATION                                             \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: CONV_FILTER                                                \n",
      "threshold_value=1.0                                                                                 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   6/1562 [..............................] - ETA: 1:41 - loss: 0.5715 - base_loss: 0.5715WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0516s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0516s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 110s 67ms/step - loss: 0.5936 - base_loss: 0.5936 - val_loss: 0.8415 - val_base_loss: 0.8415\n",
      "Epoch 2/5\n",
      "1562/1562 [==============================] - 110s 70ms/step - loss: 0.5691 - base_loss: 0.5691 - val_loss: 0.8019 - val_base_loss: 0.8019\n",
      "Epoch 3/5\n",
      "1562/1562 [==============================] - 110s 71ms/step - loss: 0.5298 - base_loss: 0.5298 - val_loss: 0.8033 - val_base_loss: 0.8033\n",
      "Epoch 4/5\n",
      "1562/1562 [==============================] - 109s 70ms/step - loss: 0.5007 - base_loss: 0.5007 - val_loss: 0.8987 - val_base_loss: 0.8987\n",
      "Epoch 5/5\n",
      "1562/1562 [==============================] - 107s 68ms/step - loss: 0.4682 - base_loss: 0.4682 - val_loss: 0.8697 - val_base_loss: 0.8697\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: NO_AGGREGATION\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: NO_AGGREGATION                                     \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: CONV_FILTER                                        \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: NO_AGGREGATION                                             \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: CONV_FILTER                                                \n",
      "threshold_value=1.0                                                                                 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   6/1562 [..............................] - ETA: 1:43 - loss: 0.4754 - base_loss: 0.4754WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_train_batch_end` time: 0.0539s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_train_batch_end` time: 0.0539s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 111s 68ms/step - loss: 0.4557 - base_loss: 0.4557 - val_loss: 0.8251 - val_base_loss: 0.8251\n",
      "Epoch 2/5\n",
      "1562/1562 [==============================] - 110s 70ms/step - loss: 0.4206 - base_loss: 0.4206 - val_loss: 0.8239 - val_base_loss: 0.8239\n",
      "Epoch 3/5\n",
      "1562/1562 [==============================] - 111s 71ms/step - loss: 0.4001 - base_loss: 0.4001 - val_loss: 0.8116 - val_base_loss: 0.8116\n",
      "Epoch 4/5\n",
      "1562/1562 [==============================] - 107s 69ms/step - loss: 0.3711 - base_loss: 0.3711 - val_loss: 0.8310 - val_base_loss: 0.8310\n",
      "Epoch 5/5\n",
      "1562/1562 [==============================] - 109s 70ms/step - loss: 0.3576 - base_loss: 0.3576 - val_loss: 0.9225 - val_base_loss: 0.9225\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: NO_AGGREGATION\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: NO_AGGREGATION                                     \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: CONV_FILTER                                        \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: NO_AGGREGATION                                             \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: CONV_FILTER                                                \n",
      "threshold_value=1.0                                                                                 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   6/1562 [..............................] - ETA: 1:42 - loss: 0.2510 - base_loss: 0.2510WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0104s vs `on_train_batch_end` time: 0.0543s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0104s vs `on_train_batch_end` time: 0.0543s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 110s 67ms/step - loss: 0.3443 - base_loss: 0.3443 - val_loss: 0.8499 - val_base_loss: 0.8499\n",
      "Epoch 2/5\n",
      "1562/1562 [==============================] - 110s 71ms/step - loss: 0.3208 - base_loss: 0.3208 - val_loss: 0.9872 - val_base_loss: 0.9872\n",
      "Epoch 3/5\n",
      "1562/1562 [==============================] - 111s 71ms/step - loss: 0.3089 - base_loss: 0.3089 - val_loss: 0.9129 - val_base_loss: 0.9129\n",
      "Epoch 4/5\n",
      "1562/1562 [==============================] - 108s 69ms/step - loss: 0.2883 - base_loss: 0.2883 - val_loss: 0.9366 - val_base_loss: 0.9366\n",
      "Epoch 5/5\n",
      "1562/1562 [==============================] - 108s 69ms/step - loss: 0.2785 - base_loss: 0.2785 - val_loss: 1.0261 - val_base_loss: 1.0261\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: NO_AGGREGATION\n",
      "CURRENT TERM: FISHER_MATRIX, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: SIGN_FLIPPING, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: NO_AGGREGATION                                     \n",
      "CURRENT TERM: MOMENTUM_BASED, AGGREGATION LEVEL: CONV_FILTER                                        \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: NO_AGGREGATION                                      \n",
      "CURRENT TERM: WEIGHT_CHANGE, AGGREGATION LEVEL: CONV_FILTER                                         \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: NO_AGGREGATION                                             \n",
      "CURRENT TERM: RANDOM, AGGREGATION LEVEL: CONV_FILTER                                                \n",
      "threshold_value=1.0                                                                                 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CIFAR10_medium_model/assets\n"
     ]
    }
   ],
   "source": [
    "def measure_val_loss_over_threshold(epoch_number, ewc_term_creators: List[EWC_Term_Creator]):\n",
    "    epoch_results = pd.DataFrame(columns=column_names)\n",
    "    for ewc_term_creator in ewc_term_creators:\n",
    "        for aggregation_level in aggregation_levels:\n",
    "            try:\n",
    "                print(f\"CURRENT TERM: {ewc_term_creator.ewc_method.name}, AGGREGATION LEVEL: {aggregation_level.name}\")\n",
    "                ewc_term = ewc_term_creator.create_term(ewc_lambda = 1, task=task)\n",
    "                method_results = validation_loss_by_importance_threshold(task, ewc_term.omega_matrix, sample_array, aggregation_level=aggregation_level, show_plot=False)\n",
    "                method_results[\"EWC Method\"] = ewc_term_creator.ewc_method.name\n",
    "                method_results[\"Aggregation Level\"] = aggregation_level.name\n",
    "                method_results[\"Epoch\"] = epoch_number\n",
    "                epoch_results = pd.concat([epoch_results, method_results], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"EXCEPTION {e}\")\n",
    "                continue\n",
    "    return epoch_results\n",
    "\n",
    "epoch_index = 0\n",
    "while epoch_index < num_epochs:\n",
    "    epoch_index += sample_period\n",
    "    task.train_on_task(epochs=sample_period, callbacks=callbacks)\n",
    "\n",
    "    all_results_dataframe = pd.concat([all_results_dataframe, measure_val_loss_over_threshold(epoch_index, ewc_term_creators)], ignore_index=True)\n",
    "    all_results_dataframe.to_csv(\"data/validation_loss_over_threshold.csv\")\n",
    "    task.model.save(filepath=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>EWC Method</th>\n",
       "      <th>Aggregation Level</th>\n",
       "      <th>Threshold Value</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>FISHER_MATRIX</td>\n",
       "      <td>NO_AGGREGATION</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.866979</td>\n",
       "      <td>0.979571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>FISHER_MATRIX</td>\n",
       "      <td>NO_AGGREGATION</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.866580</td>\n",
       "      <td>0.979861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>FISHER_MATRIX</td>\n",
       "      <td>NO_AGGREGATION</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.863429</td>\n",
       "      <td>0.978296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>FISHER_MATRIX</td>\n",
       "      <td>NO_AGGREGATION</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.861961</td>\n",
       "      <td>0.973872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FISHER_MATRIX</td>\n",
       "      <td>NO_AGGREGATION</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.860800</td>\n",
       "      <td>0.969991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>25</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>CONV_FILTER</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.308608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>25</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>CONV_FILTER</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.308389</td>\n",
       "      <td>2.308364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>25</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>CONV_FILTER</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.305713</td>\n",
       "      <td>2.305665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>25</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>CONV_FILTER</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.302805</td>\n",
       "      <td>2.302810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>25</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>CONV_FILTER</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.302731</td>\n",
       "      <td>2.302715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Epoch     EWC Method Aggregation Level  Threshold Value      Loss  \\\n",
       "0        5  FISHER_MATRIX    NO_AGGREGATION             0.00  0.866979   \n",
       "1        5  FISHER_MATRIX    NO_AGGREGATION             0.04  0.866580   \n",
       "2        5  FISHER_MATRIX    NO_AGGREGATION             0.08  0.863429   \n",
       "3        5  FISHER_MATRIX    NO_AGGREGATION             0.12  0.861961   \n",
       "4        5  FISHER_MATRIX    NO_AGGREGATION             0.16  0.860800   \n",
       "...    ...            ...               ...              ...       ...   \n",
       "1295    25         RANDOM       CONV_FILTER             0.84  2.308533   \n",
       "1296    25         RANDOM       CONV_FILTER             0.88  2.308389   \n",
       "1297    25         RANDOM       CONV_FILTER             0.92  2.305713   \n",
       "1298    25         RANDOM       CONV_FILTER             0.96  2.302805   \n",
       "1299    25         RANDOM       CONV_FILTER             1.00  2.302731   \n",
       "\n",
       "      Validation Loss  \n",
       "0            0.979571  \n",
       "1            0.979861  \n",
       "2            0.978296  \n",
       "3            0.973872  \n",
       "4            0.969991  \n",
       "...               ...  \n",
       "1295         2.308608  \n",
       "1296         2.308364  \n",
       "1297         2.305665  \n",
       "1298         2.302810  \n",
       "1299         2.302715  \n",
       "\n",
       "[1300 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "24d1b1f2d3141c0ff1635b20953f5ae3bc501888575bad739f03d5f2516fa480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
